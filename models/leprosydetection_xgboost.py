# -*- coding: utf-8 -*-
"""LeprosyDetection_XGBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IPuDc2HQ8CJyeHFggCsERVf6wWDC_2eN
"""

pip install groq

pip install whisper groq sentence-transformers scikit-learn xgboost pytorch-tabnet shap transformers

import whisper
import json
import numpy as np
import shap
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from xgboost import XGBClassifier
from pytorch_tabnet.tab_model import TabNetClassifier
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
import torch
from groq import Groq

pip install gtts

import whisper
import json
import numpy as np
from groq import Groq  # pip install groq
from pathlib import Path

from dotenv import load_dotenv
import os

load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")

SYMPTOM_LIST = [
    "white patches", "numbness", "skin lesions", "red patches", "loss of feeling",
    "tingling", "muscle weakness", "thickened skin", "dry skin", "nosebleeds",
    "eye problems", "loss of eyebrows", "thickened nerves", "facial swelling",
    "foot ulcers", "decreased pain sensation", "dark patches", "light skin lesions",
    "weak grip", "reduced sweating"
]

def transcribe_audio(audio_file):
    """Convert audio file to text using Whisper."""
    model = whisper.load_model("base")  # or "small", "medium", "large"
    result = model.transcribe(audio_file)
    return result['text']

def extract_symptoms_with_groq(user_text, api_key, symptom_list):
    """Extract relevant symptoms using Groq API and match against predefined symptoms."""
    client = Groq(api_key=api_key)
    prompt = f"""
    Analyze this text: '{user_text}'
    List only the leprosy symptoms present from this list: {symptom_list}.
    Do not include symptoms that are denied (e.g., "I do not have red spots" means red spots are not present).
    Return a JSON list of confirmed symptoms only (e.g., ["numbness", "white patches"]).
    """
    response = client.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model="llama3-8b-8192"

    )
    raw_text = response.choices[0].message.content.strip()

    try:
        extracted = json.loads(raw_text)
    except:
        # fallback to keyword match if JSON parsing fails
        extracted = [sym for sym in symptom_list if sym.lower() in user_text.lower()]
    return extracted

def create_one_hot_vector(extracted_symptoms, symptom_list):
    """Create a binary vector for presence/absence of symptoms."""
    return np.array([1 if sym in extracted_symptoms else 0 for sym in symptom_list])

from gtts import gTTS

# Your input text
text = "I have white patches on my skin and some numbness in my hands."

# Language (English)
language = 'en'

# Create the TTS object
tts = gTTS(text=text, lang=language, slow=False)

# Save as MP3 file
tts.save("symptom_description.mp3")

print("Audio file 'symptom_description.mp3' created successfully!")

if __name__ == "__main__":
    audio_path = "/content/symptom_description.mp3"  # <- change this to user input audio file

    if not Path(audio_path).exists():
        raise FileNotFoundError(f"Audio file '{audio_path}' not found.")

    # Step 1: Transcribe Audio
    transcript = transcribe_audio(audio_path)
    print("Transcription:", transcript)

    # Step 2: Extract Symptoms using Groq
    extracted_symptoms = extract_symptoms_with_groq(transcript, GROQ_API_KEY, SYMPTOM_LIST)
    print("Extracted Symptoms:", extracted_symptoms)

    # Step 3: Convert to Binary Vector
    vector = create_one_hot_vector(extracted_symptoms, SYMPTOM_LIST)
    print("Symptom Vector:", vector)

import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix

# Define your symptom list (ensure it's consistent)
SYMPTOM_LIST = [
    "white_patches", "numbness", "skin_lesions", "red_patches", "loss_of_feeling",
    "tingling", "muscle_weakness", "thickened_skin", "dry_skin", "nosebleeds",
    "eye_problems", "loss_of_eyebrows", "thickened_nerves", "facial_swelling",
    "foot_ulcers", "decreased_pain_sensation", "dark_patches", "light_skin_lesions",
    "weak_grip", "reduced_sweating"
]

# 1. Load your full training dataset
df = pd.read_csv("/content/leprosy_symptoms_dataset_balanced.csv")  # Ensure the last column is 'label'
X = df[SYMPTOM_LIST].values
y = df["label"].values

# 2. Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Train XGBoost
model = XGBClassifier(eval_metric="logloss")
model.fit(X_train, y_train)

# 4. Evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# 5. Predict on new audio
# Use symptom_vector from the previous step
prediction = model.predict([vector])[0]
print("Leprosy Prediction from audio:", "Positive" if prediction == 1 else "Negative")

import shap

# 2. Create SHAP explainer
explainer = shap.Explainer(model)

# 3. Compute SHAP values for test data
shap_values = explainer(X_test)

# 4. Plot feature importance (global)
shap.plots.bar(shap_values)

# 5. Plot explanation for one prediction
shap.plots.waterfall(shap_values[0])

